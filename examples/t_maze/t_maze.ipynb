{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Inference for the T-Maze Navigation Task\n",
    "\n",
    "This demo is based upon Part I and II of the \"Realising Synthetic Active Inference Agents\" paper series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Simulations\\RxAIF`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"../..\")\n",
    "\n",
    "using RxAIF\n",
    "using RxInfer\n",
    "\n",
    "include(\"../../src/fixes.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"helpers.jl\")\n",
    "\n",
    "# Set simulation parameters\n",
    "(A, B, C, D_0) = constructABCD(0.9, 2.0)\n",
    "r              = [1, 0] # Reward at position 2\n",
    "x_0            = zeros(8)\n",
    "x_0[1:2]       = r # Start from position 1\n",
    "\n",
    "# Environmental parameters\n",
    "env = (\n",
    "    x_0 = x_0,\n",
    "    A   = A,\n",
    "    B   = B\n",
    ")\n",
    "\n",
    "# Model parameters\n",
    "params = (\n",
    "    T = 2,\n",
    "    A = A,\n",
    "    B = B,\n",
    "    C = C\n",
    ")\n",
    "\n",
    "# Model prior statistics\n",
    "stats = Dict(\n",
    "    :D_t_min => D_0 # Initial state belief\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Generative Model and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regulator model\n",
    "@model function t_maze_plan(tau, params, stats, c)\n",
    "    x_t_min ~ Categorical(stats[:D_t_min]) # State prior\n",
    "\n",
    "    x_k_min = x_t_min\n",
    "    for k=1:tau\n",
    "        u[k] ~ Categorical(ones(4)./4)\n",
    "        x[k] ~ TransitionMixture(x_k_min, u[k], B[1], B[2], B[3], B[4]) # TODO: params.B[1] gives error\n",
    "        c[k] ~ GoalObservation(x[k], params.A) where {\n",
    "            meta         = GeneralizedMeta(), \n",
    "            dependencies = GeneralizedPipeline(vague(Categorical,8))} # With breaker message\n",
    "\n",
    "        x_k_min = x[k] # Reset for next slice\n",
    "    end\n",
    "end\n",
    "\n",
    "# Define constraints on the variational distributions\n",
    "@constraints function structured()\n",
    "    q(u) :: PointMassFormConstraint()\n",
    "end\n",
    "\n",
    "# Initialize variational distributions\n",
    "@initialization function init_marginals()\n",
    "    q(x) = Categorical(softmax(rand(8)))\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regulator model\n",
    "@model function t_maze_estimate(params, stats, y_t, u_t)\n",
    "    x_t_min ~ Categorical(stats[:D_t_min]) # State prior\n",
    "    x_t     ~ Transition(x_t_min, B[u_t]) # TODO: params.B[u_t] doesn't work\n",
    "    y_t     ~ Transition(x_t, params.A)\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Perception-Action Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"helpers.jl\")\n",
    "include(\"environment.jl\")\n",
    "include(\"agent.jl\")\n",
    "\n",
    "(execute, observe)    = initializeWorld(env) # Let there be a world\n",
    "(plan, act, estimate) = initializeAgent(params, stats) # Let there be an agent\n",
    "\n",
    "a = Vector{Int64}(undef, params.T) # Actions per time\n",
    "o = Vector{Vector}(undef, params.T) # Observations (one-hot) per time\n",
    "for t=1:params.T\n",
    "            plan(t)\n",
    "    a[t]  = act()\n",
    "            execute(a[t])\n",
    "    o[t]  = observe()\n",
    "            estimate(o[t], a[t])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Int64}:\n",
       " 4\n",
       " 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
